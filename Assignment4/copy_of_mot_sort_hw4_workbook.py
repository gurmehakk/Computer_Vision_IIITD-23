# -*- coding: utf-8 -*-
"""Copy of MOT_SORT_HW4_Workbook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19gFeSLdasdKJLGxqOTQXhKeuDiqyjqBd

## **CV HW4: Multi-object Tracking (MOT) with Detection**
**Detection**: YOLOv5, 
**Tracking**: Simple Online Realtime Tracking (SORT)

---

## **1. Unzip data folder**
"""

from google.colab import drive
drive.mount('/content/drive')

# Change the path according to your setup 
!unzip '/content/drive/MyDrive/cv2023/hw4/sort-master.zip'
!unzip '/content/drive/MyDrive/cv2023/hw4/KITTI_17_images.zip'

"""# **2. Install requirements**"""

!pip install -r sort-master/requirements.txt
!pip install cv

!pip install filterpy

"""# **3. Import libraries**"""

import torch
import torchvision
import cv2
import sys
sys.path.insert(0,'./sort-master/')
import matplotlib
from google.colab.patches import cv2_imshow
from collections import namedtuple, OrderedDict
import matplotlib as plt

"""# **4. Load YOLOv5 detector from torch hub**"""

yolov5_detector = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained = True)
yolov5_detector.float()
yolov5_detector.eval()

from PIL import Image

"""# **5. Import SORT library**"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install filterpy

from sort import *

"""#**6. Perform tracking with detection**"""

import os
import torch
import numpy as np
from sort import *
from collections import OrderedDict
mot_tracker = Sort()
image_dir = '/content/KITTI_17_images'
output_video_path = '/content/drive/MyDrive/cv2023/hw4/result.mp4'
output_file_path = '/content/bounding_boxes.txt'
Detection = namedtuple('Detection', ['frame_id', 'bbox', 'score', 'class_id'])
class_names = {0: 'pedestrian'}
for i, file in enumerate(sorted(os.listdir(image_dir))):
    detections = []
    img = cv2.imread(os.path.join(image_dir, file))
    results = yolov5_detector(img)
    for result in results.xyxy[0]:
        bbox = result[0:4].tolist()
        score = result[4].item()
        class_id = int(result[5].item())
        if class_id == 0:
            detections.append(Detection(i, bbox, score, class_id))
    # cv2_imshow(img)
    # plt.show()
    # break
    if i >= 0:
        detections_np = np.zeros((len(detections), 6))
        for j, detection in enumerate(detections):
            # print(detection)
            detections_np[j, :] = np.array([detection.frame_id, detection.bbox[0], detection.bbox[1],
                                            detection.bbox[2], detection.bbox[3], detection.score])
            
        # x = detections_np[:-1][:,1:]
        # print(x[:,1:])
        # break
        tracked_objects = mot_tracker.update(detections_np[:-1][:,1:])
        with open(output_file_path,'a') as f:
          for obj in tracked_objects:
            x1, y1, x2, y2 , obj_id = obj.tolist()
            line = '0,0,0,0 0,0,1,-1,-2,-20'.format(i+2, obj_id, x1, y1, x2-x1, y2-y1)
            f.write(line)
        # print(tracked_objects[0])
        for j in range(len(tracked_objects)):
            class_id = int(tracked_objects[j][4])
            cv2.rectangle(img, (int(tracked_objects[j][0]), int(tracked_objects[j][1])), (int(tracked_objects[j][2]), int(tracked_objects[j][3])), (0, 255, 0), 2)
        cv2_imshow(img)
        plt.show()
        cv2.destroyAllWindows()
        image_filename = '/content/'+ str(i)+'img.jpg'
        print(image_filename)
        # img = img.save(image_filename)
        cv2.imwrite(image_filename,img)

    # break
    # if i==2:
    #   break
    if i == 0:
        height, width, _ = img.shape
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        video_writer = cv2.VideoWriter(output_video_path,cv2.VideoWriter_fourcc('M','J','P','G'), 10, (width,height))

gt_file = '/content/drive/MyDrive/cv2023/hw4/gt.txt'
num = 0
with open(gt_file, 'r') as f:
    gt_lines = f.readlines()
    num = gt_lines
gt_bboxes = []
for line in gt_lines:
    line = line.split(',')
    bbox = [line[i] for i in range(6)]
    gt_bboxes.append(bbox)

pred_file = 'bounding_boxes.txt'
with open(pred_file, 'r') as f:
    pred_lines = f.readlines()
pred_bboxes = []
for line in pred_lines:
    line = line.split(',')
    bbox = [line[i+1] for i in range(6)]
    pred_bboxes.append(bbox)

# Commented out IPython magic to ensure Python compatibility.
# %pip install motmetrics
from motmetrics import metrics
from motmetrics import utils as mmutils

acc = metrics.MOTAccumulator(auto_id=True)
for i in range(len(num)):
    gt_box = gt_bboxes[i]
    pred_box = pred_bboxes[i]
    dists = []
    # for j, gt_box in enumerate(gtb):
    #     for k, pred_box in enumerate(pdb):
    x1 = max(gt_box[0], pred_box[0])
    y1 = max(gt_box[1], pred_box[1])
    x2 = min(gt_box[2], pred_box[2])
    y2 = min(gt_box[3], pred_box[3])
    intersection = max(0, int(x2) - int(x1) + 1) * max(0, int(y2) - int(y1) + 1)
    box1_area = (gt_box[2] - gt_box[0] + 1) * (gt_box[3] - gt_box[1] + 1)
    box2_area = (pred_box[2] - pred_box[0] + 1) * (pred_box[3] - pred_box[1] + 1)
    union = box1_area + box2_area - intersection
    iou = intersection / union
    dists.append(1 - iou)
    acc.update(gt_bboxes, pred_bboxes, dists)
acc.update(gt_bboxes, pred_bboxes)
metrics = metrics.compute_metrics(acc, metrics=['num_frames', 'mota', 'motp'])
print(metrics)

# We can interpret MOTA as the percentage of objects that were correctly tracked, while MOTP is a measure of the average distance between ground truth and predicted bounding boxes. Higher values of MOTA and lower values of MOTP indicate better tracking performance.

# Write your code here to perform tracking with detection using the provided YOLOv5 model and the SORT implementation

"""# **7. Report Evaluation Metrics**"""

# Use the Track-Eval kit to report the complete set of performance and accuracy metrics
# Comment on and interpret MOTA and MOTP values